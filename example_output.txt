*************** TESTING IN DATASET ICMC ***************
3-NN (1/3)
        Average accuracy: 0.985000

5-NN (2/3)
        Average accuracy: 0.940000

7-NN (3/3)
        Average accuracy: 0.895000

Best KNN has k = 3
Average accuracy: 0.985000
Precision for class 1: 1.000000
Precision for class 2: 1.000000
Precision for class 3: 0.888889
Precision for class 4: 1.000000
Precision for class 5: 1.000000
Precision for class 6: 1.000000
Precision for class 7: 1.000000
Precision for class 8: 1.000000
Precision for class 9: 1.000000
Precision for class 10: 1.000000
Precision for class 11: 1.000000
Precision for class 12: 1.000000
Precision for class 13: 1.000000
Precision for class 14: 1.000000
Precision for class 15: 1.000000
Precision for class 16: 1.000000
Precision for class 17: 1.000000
Precision for class 18: 1.000000
Precision for class 19: 0.818182
Precision for class 20: 1.000000
Confusion matrix
[[10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  8.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   2.  0.]
 [ 0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.
   0.  0.]
 [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   9.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0. 10.]]
KNN with PCA and k = 3 | # components = 25 | explained variance = 0.534688
Average accuracy: 0.970000
Precision for class 1: 1.000000
Precision for class 2: 1.000000
Precision for class 3: 1.000000
Precision for class 4: 1.000000
Precision for class 5: 1.000000
Precision for class 6: 1.000000
Precision for class 7: 0.769231
Precision for class 8: 1.000000
Precision for class 9: 1.000000
Precision for class 10: 1.000000
Precision for class 11: 1.000000
Precision for class 12: 0.769231
Precision for class 13: 1.000000
Precision for class 14: 1.000000
Precision for class 15: 1.000000
Precision for class 16: 1.000000
Precision for class 17: 1.000000
Precision for class 18: 1.000000
Precision for class 19: 1.000000
Precision for class 20: 1.000000
Confusion matrix
[[10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  8.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  9.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  1.  0.  9.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   8.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0. 10.]]
MLP hidden layers (10,) | learning_rate = 0.100000 | momentum = 0.100000  (1/36)
Average accuracy: 0.995000

MLP hidden layers (10,) | learning_rate = 0.100000 | momentum = 0.500000  (2/36)
Average accuracy: 0.990000

MLP hidden layers (10,) | learning_rate = 0.100000 | momentum = 0.900000  (3/36)
Average accuracy: 0.990000

MLP hidden layers (10,) | learning_rate = 0.500000 | momentum = 0.100000  (4/36)
Average accuracy: 0.135000

MLP hidden layers (10,) | learning_rate = 0.500000 | momentum = 0.500000  (5/36)
Average accuracy: 0.090000

MLP hidden layers (10,) | learning_rate = 0.500000 | momentum = 0.900000  (6/36)
Average accuracy: 0.065000

MLP hidden layers (10,) | learning_rate = 10.000000 | momentum = 0.100000  (7/36)
Average accuracy: 0.050000

MLP hidden layers (10,) | learning_rate = 10.000000 | momentum = 0.500000  (8/36)
Average accuracy: 0.055000

MLP hidden layers (10,) | learning_rate = 10.000000 | momentum = 0.900000  (9/36)
Average accuracy: 0.065000

MLP hidden layers (20,) | learning_rate = 0.100000 | momentum = 0.100000  (10/36)
Average accuracy: 0.995000

MLP hidden layers (20,) | learning_rate = 0.100000 | momentum = 0.500000  (11/36)
Average accuracy: 0.995000

MLP hidden layers (20,) | learning_rate = 0.100000 | momentum = 0.900000  (12/36)
Average accuracy: 1.000000

MLP hidden layers (20,) | learning_rate = 0.500000 | momentum = 0.100000  (13/36)
Average accuracy: 0.660000

MLP hidden layers (20,) | learning_rate = 0.500000 | momentum = 0.500000  (14/36)
Average accuracy: 0.140000

MLP hidden layers (20,) | learning_rate = 0.500000 | momentum = 0.900000  (15/36)
Average accuracy: 0.265000

MLP hidden layers (20,) | learning_rate = 10.000000 | momentum = 0.100000  (16/36)
Average accuracy: 0.050000

MLP hidden layers (20,) | learning_rate = 10.000000 | momentum = 0.500000  (17/36)
Average accuracy: 0.050000

MLP hidden layers (20,) | learning_rate = 10.000000 | momentum = 0.900000  (18/36)
Average accuracy: 0.060000

MLP hidden layers (10, 5) | learning_rate = 0.100000 | momentum = 0.100000  (19/36)
Average accuracy: 0.915000

MLP hidden layers (10, 5) | learning_rate = 0.100000 | momentum = 0.500000  (20/36)
Average accuracy: 0.970000

MLP hidden layers (10, 5) | learning_rate = 0.100000 | momentum = 0.900000  (21/36)
Average accuracy: 0.685000

MLP hidden layers (10, 5) | learning_rate = 0.500000 | momentum = 0.100000  (22/36)
Average accuracy: 0.085000

MLP hidden layers (10, 5) | learning_rate = 0.500000 | momentum = 0.500000  (23/36)
Average accuracy: 0.080000

MLP hidden layers (10, 5) | learning_rate = 0.500000 | momentum = 0.900000  (24/36)
Average accuracy: 0.075000

MLP hidden layers (10, 5) | learning_rate = 10.000000 | momentum = 0.100000  (25/36)
Average accuracy: 0.050000

MLP hidden layers (10, 5) | learning_rate = 10.000000 | momentum = 0.500000  (26/36)
Average accuracy: 0.050000

MLP hidden layers (10, 5) | learning_rate = 10.000000 | momentum = 0.900000  (27/36)
Average accuracy: 0.050000

MLP hidden layers (15, 10) | learning_rate = 0.100000 | momentum = 0.100000  (28/36)
Average accuracy: 0.990000

MLP hidden layers (15, 10) | learning_rate = 0.100000 | momentum = 0.500000  (29/36)
Average accuracy: 0.990000

MLP hidden layers (15, 10) | learning_rate = 0.100000 | momentum = 0.900000  (30/36)
Average accuracy: 0.970000

MLP hidden layers (15, 10) | learning_rate = 0.500000 | momentum = 0.100000  (31/36)
Average accuracy: 0.160000

MLP hidden layers (15, 10) | learning_rate = 0.500000 | momentum = 0.500000  (32/36)
Average accuracy: 0.120000

MLP hidden layers (15, 10) | learning_rate = 0.500000 | momentum = 0.900000  (33/36)
Average accuracy: 0.070000

MLP hidden layers (15, 10) | learning_rate = 10.000000 | momentum = 0.100000  (34/36)
Average accuracy: 0.050000

MLP hidden layers (15, 10) | learning_rate = 10.000000 | momentum = 0.500000  (35/36)
Average accuracy: 0.050000

MLP hidden layers (15, 10) | learning_rate = 10.000000 | momentum = 0.900000  (36/36)
Average accuracy: 0.050000

Best MLP has hidden layers = (20,) | learning_rate = 0.100000 | momentum = 0.900000
Average accuracy: 1.000000
Precision for class 1: 1.000000
Precision for class 2: 1.000000
Precision for class 3: 1.000000
Precision for class 4: 1.000000
Precision for class 5: 1.000000
Precision for class 6: 1.000000
Precision for class 7: 1.000000
Precision for class 8: 1.000000
Precision for class 9: 1.000000
Precision for class 10: 1.000000
Precision for class 11: 1.000000
Precision for class 12: 1.000000
Precision for class 13: 1.000000
Precision for class 14: 1.000000
Precision for class 15: 1.000000
Precision for class 16: 1.000000
Precision for class 17: 1.000000
Precision for class 18: 1.000000
Precision for class 19: 1.000000
Precision for class 20: 1.000000
Confusion matrix
[[10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  10.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0. 10.]]
MLP with PCA and hidden layers = (20,) | learning_rate = 0.100000 | momentum = 0.900000 | # components = 25 | explained variance = 0.534688
Average accuracy: 0.995000
Precision for class 1: 1.000000
Precision for class 2: 1.000000
Precision for class 3: 0.909091
Precision for class 4: 1.000000
Precision for class 5: 1.000000
Precision for class 6: 1.000000
Precision for class 7: 1.000000
Precision for class 8: 1.000000
Precision for class 9: 1.000000
Precision for class 10: 1.000000
Precision for class 11: 1.000000
Precision for class 12: 1.000000
Precision for class 13: 1.000000
Precision for class 14: 1.000000
Precision for class 15: 1.000000
Precision for class 16: 1.000000
Precision for class 17: 1.000000
Precision for class 18: 1.000000
Precision for class 19: 1.000000
Precision for class 20: 1.000000
Confusion matrix
[[10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.
   0.  0.]
 [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   9.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0. 10.]]
*************** TESTING IN DATASET ORL ***************
3-NN (1/3)
        Average accuracy: 0.945000

5-NN (2/3)
        Average accuracy: 0.895000

7-NN (3/3)
        Average accuracy: 0.870000

Best KNN has k = 3
Average accuracy: 0.945000
Precision for class 1: 0.833333
Precision for class 2: 1.000000
Precision for class 3: 0.909091
Precision for class 4: 1.000000
Precision for class 5: 1.000000
Precision for class 6: 0.909091
Precision for class 7: 0.909091
Precision for class 8: 1.000000
Precision for class 9: 1.000000
Precision for class 10: 1.000000
Precision for class 11: 1.000000
Precision for class 12: 0.833333
Precision for class 13: 1.000000
Precision for class 14: 1.000000
Precision for class 15: 0.909091
Precision for class 16: 0.888889
Precision for class 17: 0.909091
Precision for class 18: 1.000000
Precision for class 19: 1.000000
Precision for class 20: 0.900000
Confusion matrix
[[10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  8.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.
   0.  1.]
 [ 0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 2.  0.  0.  0.  0.  1.  0.  7.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  9.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  8.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.
   0.  0.]
 [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  1.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  10.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.
   0.  9.]]
KNN with PCA and k = 3 | # components = 50 | explained variance = 0.527936
Average accuracy: 0.925000
Precision for class 1: 0.769231
Precision for class 2: 1.000000
Precision for class 3: 0.833333
Precision for class 4: 1.000000
Precision for class 5: 1.000000
Precision for class 6: 0.909091
Precision for class 7: 1.000000
Precision for class 8: 0.888889
Precision for class 9: 1.000000
Precision for class 10: 0.833333
Precision for class 11: 1.000000
Precision for class 12: 0.833333
Precision for class 13: 1.000000
Precision for class 14: 1.000000
Precision for class 15: 0.900000
Precision for class 16: 0.888889
Precision for class 17: 0.909091
Precision for class 18: 1.000000
Precision for class 19: 1.000000
Precision for class 20: 0.888889
Confusion matrix
[[10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  8.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.
   0.  1.]
 [ 0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  2.  0.  8.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 2.  0.  0.  0.  0.  0.  0.  8.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  9.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  8.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  9.  0.  0.  0.  0.
   0.  0.]
 [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  9.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  8.  1.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  10.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.
   0.  8.]]
MLP hidden layers (10,) | learning_rate = 0.100000 | momentum = 0.100000  (1/36)
Average accuracy: 0.930000

MLP hidden layers (10,) | learning_rate = 0.100000 | momentum = 0.500000  (2/36)
Average accuracy: 0.940000

MLP hidden layers (10,) | learning_rate = 0.100000 | momentum = 0.900000  (3/36)
Average accuracy: 0.925000

MLP hidden layers (10,) | learning_rate = 0.500000 | momentum = 0.100000  (4/36)
Average accuracy: 0.060000

MLP hidden layers (10,) | learning_rate = 0.500000 | momentum = 0.500000  (5/36)
Average accuracy: 0.050000

MLP hidden layers (10,) | learning_rate = 0.500000 | momentum = 0.900000  (6/36)
Average accuracy: 0.050000

MLP hidden layers (10,) | learning_rate = 10.000000 | momentum = 0.100000  (7/36)
Average accuracy: 0.050000

MLP hidden layers (10,) | learning_rate = 10.000000 | momentum = 0.500000  (8/36)
Average accuracy: 0.050000

MLP hidden layers (10,) | learning_rate = 10.000000 | momentum = 0.900000  (9/36)
Average accuracy: 0.050000

MLP hidden layers (20,) | learning_rate = 0.100000 | momentum = 0.100000  (10/36)
Average accuracy: 0.955000

MLP hidden layers (20,) | learning_rate = 0.100000 | momentum = 0.500000  (11/36)
Average accuracy: 0.960000

MLP hidden layers (20,) | learning_rate = 0.100000 | momentum = 0.900000  (12/36)
Average accuracy: 0.960000

MLP hidden layers (20,) | learning_rate = 0.500000 | momentum = 0.100000  (13/36)
Average accuracy: 0.050000

MLP hidden layers (20,) | learning_rate = 0.500000 | momentum = 0.500000  (14/36)
Average accuracy: 0.050000

MLP hidden layers (20,) | learning_rate = 0.500000 | momentum = 0.900000  (15/36)
Average accuracy: 0.060000

MLP hidden layers (20,) | learning_rate = 10.000000 | momentum = 0.100000  (16/36)
Average accuracy: 0.050000

MLP hidden layers (20,) | learning_rate = 10.000000 | momentum = 0.500000  (17/36)
Average accuracy: 0.050000

MLP hidden layers (20,) | learning_rate = 10.000000 | momentum = 0.900000  (18/36)
Average accuracy: 0.050000

MLP hidden layers (10, 5) | learning_rate = 0.100000 | momentum = 0.100000  (19/36)
Average accuracy: 0.225000

MLP hidden layers (10, 5) | learning_rate = 0.100000 | momentum = 0.500000  (20/36)
Average accuracy: 0.215000

MLP hidden layers (10, 5) | learning_rate = 0.100000 | momentum = 0.900000  (21/36)
Average accuracy: 0.095000

MLP hidden layers (10, 5) | learning_rate = 0.500000 | momentum = 0.100000  (22/36)
Average accuracy: 0.050000

MLP hidden layers (10, 5) | learning_rate = 0.500000 | momentum = 0.500000  (23/36)
Average accuracy: 0.050000

MLP hidden layers (10, 5) | learning_rate = 0.500000 | momentum = 0.900000  (24/36)
Average accuracy: 0.050000

MLP hidden layers (10, 5) | learning_rate = 10.000000 | momentum = 0.100000  (25/36)
Average accuracy: 0.050000

MLP hidden layers (10, 5) | learning_rate = 10.000000 | momentum = 0.500000  (26/36)
Average accuracy: 0.050000

MLP hidden layers (10, 5) | learning_rate = 10.000000 | momentum = 0.900000  (27/36)
Average accuracy: 0.050000

MLP hidden layers (15, 10) | learning_rate = 0.100000 | momentum = 0.100000  (28/36)
Average accuracy: 0.880000

MLP hidden layers (15, 10) | learning_rate = 0.100000 | momentum = 0.500000  (29/36)
Average accuracy: 0.835000

MLP hidden layers (15, 10) | learning_rate = 0.100000 | momentum = 0.900000  (30/36)
Average accuracy: 0.310000

MLP hidden layers (15, 10) | learning_rate = 0.500000 | momentum = 0.100000  (31/36)
Average accuracy: 0.095000

MLP hidden layers (15, 10) | learning_rate = 0.500000 | momentum = 0.500000  (32/36)
Average accuracy: 0.050000

MLP hidden layers (15, 10) | learning_rate = 0.500000 | momentum = 0.900000  (33/36)
Average accuracy: 0.055000

MLP hidden layers (15, 10) | learning_rate = 10.000000 | momentum = 0.100000  (34/36)
Average accuracy: 0.055000

MLP hidden layers (15, 10) | learning_rate = 10.000000 | momentum = 0.500000  (35/36)
Average accuracy: 0.050000

MLP hidden layers (15, 10) | learning_rate = 10.000000 | momentum = 0.900000  (36/36)
Average accuracy: 0.050000

Best MLP has hidden layers = (20,) | learning_rate = 0.100000 | momentum = 0.500000
Average accuracy: 0.960000
Precision for class 1: 1.000000
Precision for class 2: 1.000000
Precision for class 3: 1.000000
Precision for class 4: 0.909091
Precision for class 5: 0.714286
Precision for class 6: 1.000000
Precision for class 7: 1.000000
Precision for class 8: 1.000000
Precision for class 9: 1.000000
Precision for class 10: 1.000000
Precision for class 11: 1.000000
Precision for class 12: 1.000000
Precision for class 13: 1.000000
Precision for class 14: 0.900000
Precision for class 15: 1.000000
Precision for class 16: 0.833333
Precision for class 17: 1.000000
Precision for class 18: 1.000000
Precision for class 19: 1.000000
Precision for class 20: 1.000000
Confusion matrix
[[ 9.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  8.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.
   0.  0.]
 [ 0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  1.  0.  0.  9.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  9.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  9.  0.  1.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  8.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  10.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0. 10.]]
MLP with PCA and hidden layers = (20,) | learning_rate = 0.100000 | momentum = 0.500000 | # components = 50 | explained variance = 0.527936
Average accuracy: 0.945000
Precision for class 1: 0.900000
Precision for class 2: 1.000000
Precision for class 3: 1.000000
Precision for class 4: 0.833333
Precision for class 5: 0.900000
Precision for class 6: 0.833333
Precision for class 7: 1.000000
Precision for class 8: 1.000000
Precision for class 9: 1.000000
Precision for class 10: 0.833333
Precision for class 11: 1.000000
Precision for class 12: 1.000000
Precision for class 13: 1.000000
Precision for class 14: 1.000000
Precision for class 15: 0.900000
Precision for class 16: 0.800000
Precision for class 17: 1.000000
Precision for class 18: 1.000000
Precision for class 19: 1.000000
Precision for class 20: 1.000000
Confusion matrix
[[ 9.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  8.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.
   0.  0.]
 [ 0.  0.  9.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  9.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  1.  0.  9.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.
   0.  0.]
 [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  9.  0.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  8.  0.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  9.  0.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.
   0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  10.  0.]
 [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  9.]]
